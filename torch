# model save and load
#################################################
torch.save(model, path)                             # 모델 전체
torch.save(model.state_dict(), path)                # weight 만
torch.save(model.state_dict(), 'weights_only.pth')  # 사용방법

#model load
#################################################
model_new = torch.load(path.pth)                    # 모델 전체
model_new = NeuralNet()           # weight만 load 할때는 architecture가 필요함
model_new.load_state_dict(torch.load(path.pth)) 

####### cpu로 load
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
A.load_state_dict(torch.load('A.pth', map_location=device))   

#################################################

def preprocessing_datacopy(base_path, file_name):
"""
data copy and split
"""

    os.mkdir('/content/dataset')
    original_dataset_dir = os.path.join(base_path, file_name)

    classes_list = os.listdir(original_dataset_dir)

    base_dir = '/content/splitted'
    os.mkdir(base_dir)

    train_dir = os.path.join(base_dir, 'train')
    os.mkdir(train_dir)
    validation_dir = os.path.join(base_dir,'val')
    os.mkdir(validation_dir)
    test_dir = os.path.join(base_dir,'test')
    os.mkdir(test_dir)



    for clss in classes_list:
        os.mkdir(os.path.join(train_dir, clss))
        os.mkdir(os.path.join(validation_dir, clss))
        os.mkdir(os.path.join(test_dir, clss))


    for clss in classes_list:
        path = os.path.join(original_dataset_dir, clss)
        fnames = os.listdir(path)

        train_size = math.floor(len(fnames) * .6)
        validation_size = math.floor(len(fnames) * .2)
        test_size = math.floor(len(fnames) * .2)

        train_fnames = fnames[:train_size]
        print(f'train size: {clss}   file size: {len(train_fnames)}')
        for fname in train_fnames:
            src = os.path.join(path, fname)
            dst = os.path.join(os.path.join(train_dir, clss), fname)
            shutil.copyfile(src, dst)


        validation_fnames = fnames[train_size : validation_size + train_size]
        print(f'validation size: {clss} file size: {len(validation_fnames)}')

        for fname in validation_fnames:
            src = os.path.join(path, fname)
            dst = os.path.join(os.path.join(validation_dir,clss), fname)
            shutil.copyfile(src, dst)

        test_fnames = fnames[train_size : test_size + train_size]
        print(f'test size: {clss} file size: {len(test_fnames)}')

        for fname in test_fnames:
            src = os.path.join(path, fname)
            dst = os.path.join(os.path.join(test_dir, clss), fname)
            shutil.copyfile(src, dst)
